import tensorflow as tf
import numpy as np
import sys
from prepare_non_windowed_data import getEncoderDecoderData
from BatchIterator import *
from reader import *

NUM_ENC_FEATURES = 5
NUM_DEC_FEATURES = 5
NUM_LABELS = 12
MAX_STEPS = 1000
SPLIT=0.8
TRAIN_END=(int)(MAX_STEPS*SPLIT)
BATCH_SIZE = 128
START_EPOCH=0
END_EPOCH=1000
NUM_EPOCHS=1000
USE_CKPT=False
write_file='mum-cross-2.csv'
CKPT_FILE=os.getcwd()+'/ckpt/'+'congestion_model-10.meta'
LR = 0.0005
THRESHOLD = 0.5
CLASS_WEIGHTS = [1, 1]

SEED = 123 # set graph-level seed to make the random sequences generated by all ops be repeatable across sessions
tf.set_random_seed(SEED)
np.random.seed(SEED)


def getListSlice(input):
    trainList = list()
    for loc in input:
        tsList = list()
        for i in range(min(len(loc), TRAIN_END)):
            tsList.append(loc[i])
        trainList.append(tsList)
    return trainList


def encoderDecoderModel(encoderInput, \
        encoderOutput, \
        decoderInput, \
        decoderOutput, \
        seqlen, \
        state_size, \
        decoder_filters, \
        num_dec_features, \
        num_labels):

    num_samples, num_enc_steps = tf.shape(encoderInput)[0], tf.shape(encoderInput)[1]
    num_dec_steps = tf.shape(decoderInput)[1]
    N=num_labels*num_dec_features
    ## Encoder
    cell = tf.contrib.rnn.LSTMCell(state_size,state_is_tuple=True)
    encoderOutput = tf.concat([tf.zeros([num_samples,1]), encoderOutput[:,:-1]], axis=1)
    rnn_inputs = tf.concat([tf.expand_dims(encoderOutput, axis=-1), encoderInput], axis=2)
    rnn_outputs, final_state = tf.nn.dynamic_rnn(cell, rnn_inputs, sequence_length=seqlen, dtype=tf.float32)
    print(rnn_outputs.get_shape())
    decoderInput = tf.reshape(decoderInput,[tf.shape(decoderInput)[0],tf.shape(decoderInput)[1],N])
    print(decoderInput.get_shape())
    inp = tf.concat([rnn_outputs,decoderInput],axis=2)
    print(inp.get_shape())
    #encoder_out = tf.layers.dense(inp, num_labels, activation=tf.nn.relu)
    #print(encoder_out.get_shape())
    decoder_h1 = tf.layers.dense(inp, decoder_filters, activation=tf.nn.relu)
    print(decoder_h1.get_shape())
    logits = tf.layers.dense(decoder_h1, num_labels)
    print(logits.get_shape())
    #decoder_out = tf.squeeze(decoder_out, axis=3)
    #logits = encoder_out + decoder_out

    seqlen_mask = tf.slice(tf.gather(lower_triangular_ones, seqlen-1), [0, 0], [num_samples, num_dec_steps])
    seqlen_mask = tf.expand_dims(seqlen_mask, axis=-1)
    predictions = tf.nn.sigmoid(logits)

    predHist = tf.concat([tf.zeros([tf.shape(predictions)[0], \
                                    1, tf.shape(predictions)[2]]), \
                            predictions[:, :-1, :]], axis=1)

    predictionsInt = tf.cast((predictions>=0.5), 'float32')
    predHistInt = tf.cast((predHist>=0.5), 'float32')

    decoderOutputHist = tf.concat([tf.zeros([tf.shape(decoderOutput)[0],1,tf.shape(decoderOutput)[2]]),\
                                 decoderOutput[:,:-1,:]],axis=1)

    # ------ Various Losses ------ #
    # decoderOutputLoss = -(CLASS_WEIGHTS[1]*decoderOutput * tf.log(predictions+1e-9) \
    #           + CLASS_WEIGHTS[0]*(1.0-decoderOutput) * tf.log(1-predictions+1e-9))

    # decoderOutputLoss = -(decoderOutput * tf.log(predictions + 1e-9) \
    #                       + (1.0 - decoderOutput) * tf.log(1 - predictions + 1e-9))  \
    #                       + tf.cast((tf.abs(tf.subtract(predictions,predHist))>=0.4),\
    #                       'float32')*tf.square(predictions-predHist)

    
    # decoderOutputLoss = -(decoderOutput * tf.log(predictions + 1e-9) \
    #                       + (1.0 - decoderOutput) * tf.log(1 - predictions + 1e-9)) \
    #                     + tf.maximum(tf.abs(tf.subtract(predictions, predHist))-0.5,0)

    # decoderOutputLoss= -(decoderOutput * tf.log(predictions + 1e-9) \
    #                        + (1.0 - decoderOutput) * tf.log(1 - predictions + 1e-9))  \
    #                      + tf.cast((predictions>=0.5),'float32')*(tf.abs(tf.subtract(tf.log(predictions+ 1e-9),tf.log(predHist +1e-9))))


    # Regularization Loss
    #reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)
    #reg_constant = 0.001  # Choose an appropriate one.

    # decoderOutputLoss = -( decoderOutput * tf.log(predictions + 1e-9) \
    #                        + (1.0 - decoderOutput) * tf.log(1 - predictions + 1e-9)) + tf.abs(tf.abs(tf.subtract(predictionsInt, decoderOutput))+tf.abs(tf.subtract(predHistInt,decoderOutputHist)))

    #decoderOutputLoss += sum(reg_losses)*reg_constant

    # decoderOutputLoss = -( decoderOutput * tf.log(predictions + 1e-9) \
    #                        + (1.0 - decoderOutput) * tf.log(1 - predictions + 1e-9)) + \
    #                     tf.cast((predictions>=0.5),'float32')*tf.abs((predictionsInt-decoderOutput)-(predHistInt-decoderOutputHist))

    decoderOutputLoss = tf.reshape(decoderOutputLoss, [num_samples, num_dec_steps, num_labels])

    decoderOutputLoss *= seqlen_mask
    decoderOutputLoss = tf.reduce_sum(decoderOutputLoss)
    predictions *= seqlen_mask

    return decoderOutputLoss, seqlen_mask, predictions


X_enc = tf.placeholder(shape=[None, None, NUM_ENC_FEATURES],
        dtype=tf.float32) #Features of history data (encoder input)
Y_enc = tf.placeholder(shape=[None, None], 
        dtype=tf.float32) #Labels of history data (encoder output) 
X_dec = tf.placeholder(shape=[None, None, NUM_LABELS, NUM_DEC_FEATURES],
        dtype=tf.float32) #Features of next 24 hours, sampled by 5 mins (decoder input) 
Y_dec = tf.placeholder(shape=[None, None, NUM_LABELS],
        dtype=tf.float32) #Labels of next 24 hours, sampled by 5 mins (decoder output)
seqlen = tf.placeholder(tf.int32, shape=[None]) #List of lengths of each sequence
lower_triangular_ones = tf.constant(np.tril(np.ones([MAX_STEPS,MAX_STEPS])),dtype=tf.float32)


def train(encoderInput, encoderOutput, decoderInput, decoderOutput):

    decoderOutputLoss, seqlen_mask, predictions = \
            encoderDecoderModel(X_enc, Y_enc, X_dec, Y_dec, seqlen, \
            state_size=64, decoder_filters=10, \
            num_dec_features=NUM_DEC_FEATURES, num_labels=NUM_LABELS)

    file = os.getcwd()+'/results/'+ write_file
    write = open(file, 'w')
    #print(encoderOutput.get_shape())

    #print(predictions)
    binary_predictions = tf.cast((predictions >= THRESHOLD), 'float32')
    correct = tf.cast(tf.equal(tf.cast((predictions >= THRESHOLD),'float32'), Y_dec), 'float32')
    correct_pos = tf.multiply(correct, Y_dec)
    correct_pos = tf.multiply(correct_pos, seqlen_mask)
    incorrect_pos = tf.multiply(1.0 - correct, Y_dec)
    incorrect_pos = tf.multiply(incorrect_pos, seqlen_mask)
    total_pos = Y_dec
    total_neg = tf.multiply((1.0-Y_dec), seqlen_mask)
    correct_neg = tf.multiply(correct, (1.0-Y_dec))
    correct_neg = tf.multiply(correct_neg, seqlen_mask)
    incorrect_neg = tf.multiply(1.0-correct, 1.0-Y_dec)
    incorrect_neg = tf.multiply(incorrect_neg, seqlen_mask)
    accuracy_pos = tf.divide(tf.reduce_sum(tf.cast(correct_pos, 'float32')),
            tf.cast(tf.reduce_sum(total_pos), 'float32'))
    accuracy_neg = tf.divide(tf.reduce_sum(tf.cast(correct_neg, 'float32')),
            tf.cast(tf.reduce_sum(total_neg), 'float32'))

    train_variables = tf.trainable_variables()
    #print(map(lambda x: x.op.name, train_variables))

    train_op = tf.train.AdamOptimizer(learning_rate=LR).minimize(decoderOutputLoss, var_list=train_variables)

    # run

    # Add ops to save and restore all the variables.
    saver = tf.train.Saver()

    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.33, allow_growth=True)
    sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, gpu_options=gpu_options))
    if USE_CKPT:
        saver = tf.train.import_meta_graph(CKPT_FILE)
        saver.restore(sess, tf.train.latest_checkpoint('./ckpt/'))
    else:
        sess.run(tf.global_variables_initializer())

    # Train Data
    encoderInputTrain=getListSlice(encoderInput)
    encoderOutputTrain=getListSlice(encoderOutput)
    decoderInputTrain=getListSlice(decoderInput)
    decoderOutputTrain=getListSlice(decoderOutput)

    ## Train
    encoderInputItr = EncoderInputIterator(encoderInputTrain)
    encoderOutputItr = EncoderOutputIterator(encoderOutputTrain)
    decoderInputItr = DecoderInputIterator(decoderInputTrain)
    decoderOutputItr = DecoderOutputIterator(decoderOutputTrain)
    num_batches = int(encoderInputItr.size / BATCH_SIZE + (encoderInputItr.size%BATCH_SIZE>0))
    model_predictions=object()
    for epoch_no in range(START_EPOCH, END_EPOCH):
        saver.save(sess, './ckpt/congestion_model', global_step=epoch_no)
        epoch_loss = 0.0
        for batch_no in range(num_batches):
            encoderInputBch, encoderInputBchLens = encoderInputItr.batch(BATCH_SIZE)
            encoderOutputBch, encoderOutputBchLens = encoderOutputItr.batch(BATCH_SIZE)
            decoderInputBch, decoderInputBchLens = decoderInputItr.batch(BATCH_SIZE)
            decoderOutputBch, decoderOutputBchLens = decoderOutputItr.batch(BATCH_SIZE)
            #print('Epoch: {}, Batch: {},'.format(epoch_no, batch_no))
            decoderOutputLossRet, _, pred = sess.run([decoderOutputLoss,train_op, binary_predictions],
                    feed_dict={X_enc:encoderInputBch,
                        Y_enc:encoderOutputBch,
                        X_dec:decoderInputBch,
                        Y_dec:decoderOutputBch,
                        seqlen:encoderInputBchLens})
            epoch_loss += decoderOutputLossRet
            #print(pred.shape)
            model_predictions=pred
            #print('Epoch:', epoch_no, 'Batch:', batch_no, 'loss:' , decoderOutputLossRet)

        if epoch_no%2==0:
            print('Epoch', epoch_no, 'completed, loss:', epoch_loss)
            encoderInputEvalItr = EncoderInputIterator(encoderInput)
            encoderOutputEvalItr = EncoderOutputIterator(encoderOutput)
            decoderInputEvalItr = DecoderInputIterator(decoderInput)
            decoderOutputEvalItr = DecoderOutputIterator(decoderOutput)
            correct_ones, correct_zeros, incorrect_ones, incorrect_zeros, total_ones, total_zeros = 0, 0, 0, 0, 0 ,0
            for batch_no in range(num_batches):
                encoderInputBch, encoderInputBchLens = encoderInputEvalItr.batch(BATCH_SIZE)
                encoderOutputBch, encoderOutputBchLens = encoderOutputEvalItr.batch(BATCH_SIZE)
                decoderInputBch, decoderInputBchLens = decoderInputEvalItr.batch(BATCH_SIZE)
                decoderOutputBch, decoderOutputBchLens = decoderOutputEvalItr.batch(BATCH_SIZE)
                correct_pos_ret, correct_neg_ret, incorrect_pos_ret, incorrect_neg_ret, total_pos_ret, total_neg_ret, \
                                =  sess.run([correct_pos, correct_neg, incorrect_pos, incorrect_neg, total_pos, total_neg],
                                        feed_dict={X_enc:encoderInputBch,
                                        Y_enc:encoderOutputBch,
                                        X_dec:decoderInputBch,
                                        Y_dec:decoderOutputBch,
                                        seqlen:encoderInputBchLens})
                #print(correct_pos_ret.shape)
                correct_ones += np.sum(correct_pos_ret[:,TRAIN_END:,:])
                incorrect_ones += np.sum(incorrect_pos_ret[:,TRAIN_END:,:])
                correct_zeros += np.sum(correct_neg_ret[:,TRAIN_END:,:])
                incorrect_zeros += np.sum(incorrect_neg_ret[:,TRAIN_END:,:])
                total_ones += np.sum(total_pos_ret[:,TRAIN_END:,:])
                total_zeros += np.sum(total_neg_ret[:,TRAIN_END:,:])
                #print(len(total_pos_ret))
                #print(total_pos_ret[:,TRAIN_END:MAX_STEPS,:])
                #print(total_neg_ret[:,TRAIN_END:MAX_STEPS,:])
                #print(TRAIN_END)
                #print(total_zeros)
            recall_1 = correct_ones*1.0/total_ones
            precision_1 = correct_ones*1.0/(correct_ones+incorrect_zeros)
            f1_score_1 = 2*recall_1*precision_1/(recall_1+precision_1)
            recall_0 = correct_zeros*1.0/total_zeros
            precision_0 = correct_zeros*1.0/(correct_zeros+incorrect_ones)
            f1_score_0 = 2*recall_0*precision_0/(recall_0+precision_0)
            print('Total Predicted Zeros', correct_zeros+incorrect_ones)
            print('Total Zeros', total_zeros)
            print('Total Predicted Ones', correct_ones+incorrect_zeros)
            print('Total Ones', total_ones)
            print('Recall 1s:', recall_1)
            print('Precision 1s:', precision_1)
            print('Recall 0s:', recall_0)
            print('Precision 0s:', precision_0)
            print('F1 Score 1s:', f1_score_1)
            print('F1 Score 0s:', f1_score_0)
            print('--------------------')
            write.write(str(epoch_no)+','+str(epoch_loss)+','+str(recall_0)+','+str(recall_1)+',')
            write.write(str(precision_0)+','+str(precision_1)+','+str(f1_score_0)+','+str(f1_score_1)+'\n')
    #print(model_predictions[model_predictions == 1])
    return model_predictions



# def main():
#     filePath = sys.argv[1]
#     rawencoderInput, encoderInput, encoderOutput, decoderInput, decoderOutput, pos_sam_list, cong_sam_list \
#             = getEncoderDecoderData(filePath)
#     labels_list_flat = list()
#     for i in range(len(decoderOutput)):
#         for j in range(len(decoderOutput[i])):
#             labels_list_flat.append(decoderOutput[i][j])
#     labels_list_flat = np.array(labels_list_flat)
#     print(np.array(labels_list_flat).sum(axis=0))
#     print((1.0-np.array(labels_list_flat)).sum(axis=0))
# #    for i in range(len(decoderInput)):
# #        for j in range(len(decoderInput[i])):
# #            decoderInput[i][j] = decoderInput[i][j][50:50+NUM_LABELS]
# #            decoderOutput[i][j] = decoderOutput[i][j][50:50+NUM_LABELS]
#
#     model_predictions = train(encoderInput, encoderOutput, decoderInput, decoderOutput)
#     #print(encoderInput.shape)
#     #get_plot(model_predictions, decoderOutput)

def main():
    filePath = sys.argv[1]
    encoderInput, encoderOutput, decoderInput, decoderOutput \
            = getEncoderDecoderData(filePath)
    train(encoderInput, encoderOutput, decoderInput, decoderOutput)

if __name__ == '__main__':
    main()
